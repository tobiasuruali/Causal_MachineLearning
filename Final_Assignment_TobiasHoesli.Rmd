---
title: "Assignment"
subtitle: "Causal ML Luzern"
author: "Tobias Hösli"
date: "`r format(Sys.time(), '%m/%y')`"
output: 
  html_notebook:
    toc: true
    toc_float: true
    code_folding: show
---

<br>

# Theory recap: Double ML (20 points)
*Briefly describe in your own words (and potentially formulas) the general idea of Double Machine Learning. What is the crucial property that makes it work? What should the nuisance parameter predictions fulfill for Double ML to work?*

<br>

Double Machine Learning (DML) is a method for estimating treatment effects in the presence of many observed covariates. Let $Y$ denote the outcome variable, $W|D$ denote the treatment variable and $X$ denote the vector of covariates. The goal of DML is to estimate the average treatment effect $\theta_0 = E[Y(1) - Y(0)]$, where $Y(d)$ denotes the potential outcome under treatment level $d \in {0, 1}$.

Classical statistical approaches may not be applicable when there are many covariates or when their effect on the treatment and outcome cannot be satisfactorily modeled by parametric functions. DML addresses this issue by using machine learning methods to estimate nuisance functions that allow us to isolate the effect of the treatment from other factors.

The first step in DML is to estimate two nuisance functions: (1) The conditional expectation function of the outcome given covariates and treatment: $\hat{\mu}(X,D) = E[Y|X,D]$; and (2) The propensity score function: $\hat{e}(X) = E[D|X]$. To account for confounding variables and lessen bias in treatment effect estimations, these nuisance parameters are used and can be estimated using flexible machine learning methods.

Next, we compute an orthogonal score function based on these estimates. For example, in a partially linear regression model with a binary treatment variable, we can use Neyman’s orthogonal score function: *($W$ is the data, $Y$ the outcome variable, $D$ the treatment variable and $X$ covariates)*

$$
\varphi(W; \theta, \eta)=\varphi(W; \theta, g, m)=(Y - \theta D - g(X)) (D-m(X))
$$

The average treatment effect (ATE) can then be estimated as:


$$
\begin{aligned}
\hat{\tau}_{ATE} &= \frac{1}{n}\sum_{i=1}^n \psi(W_i;\theta,\eta) \\
\psi(W ; \theta, \eta) & :=g(1, X)-g(0, X)+\frac{D(Y-g(1, X))}{m(X)}-\frac{(1-D)(Y-g(0, X))}{1-m(x)}-\theta \\
& =\psi_a(W ; \eta) \theta+\psi_b(W ; \eta)
\end{aligned}
$$

One advantage of DML over other methods for estimating treatment effects is its ability to handle high-dimensional data and non-parametric relationships between covariates and outcomes. This makes it well-suited for applications where there are many potential confounders or where it is difficult to specify a parametric model for their relationship with outcomes.

Double Machine Learning (DML) provides a powerful tool for estimating treatment effects in situations where traditional statistical approaches may not be applicable due to high dimensionality or complex relationships between covariates and outcomes.But for DML to work,predictions of nuisance parameters must be low-biased and meet regularity conditions. 


<br>


# Practice task: Average effects with and without instrument (60 points)

## 401(k) dataset 

We again use the data of the `hdm` package. The data was used in [Chernozhukov and Hansen (2004)](https://direct.mit.edu/rest/article/86/3/735/57586/The-Effects-of-401-K-Participation-on-the-Wealth). Their paper investigates the effect of participation in the employer-sponsored 401(k) retirement savings plan (*p401*) on net assets (*net_tfa*). Since then, the data was used to showcase many new methods. It is not the most comprehensive dataset with basically ten covariates/regressors/predictors:

- *age*: age

- *db*: defined benefit pension

- *educ*: education (in years)

- *fsize*: family size

- *hown*: home owner

- *inc*: income (in US $)

- *male*: male

- *marr*: married

- *pira*: participation in individual retirement account (IRA)

- *twoearn*: two earners

```{r, warning=F,message=F}
library(hdm)
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(mlr3tuning)
library(ggplot2)

# Get data
data(pension)
# Outcome
Y <-  pension$net_tfa
# Treatment
W <-  pension$p401
# Treatment
Z <-  pension$e401
# Create main effects matrix
X <-  model.matrix(~ 0 + age + db + educ + fsize + hown + inc + male + marr + pira + twoearn, data = pension)


#collect all columns in a single data.table
data_pension <- data.table(cbind(X,W,Z,Y))
cols <- colnames(data_pension)
# remove columns Y,W,Z from cols
cols <- cols[!cols %in% c("Y", "W", "Z")]

```


## Partially linear regression model (PLR)

We have a regression problem because our outcome variable, net tfa, which represents net assets, is continuous in nature. Regression learners will be used to model the relationship between our predictor coefficients $X$ and the outcome variable $Y$.
The outcome variable $Y$ is modeled as a linear function of the policy variable $D$ and additional confounding factors $X$ in a partly linear regression model (PLR). The model's objective is to determine the causal relationship between $D$ and $Y$ while accounting for the impact of $X$. Since our outcome variable is continous a regression learner will always be utuilized for $Y$.
For $D$ it is appropiate to use a classification learner, since $D$ (`e401`) is a binary value.



### Version I (Regression Random Forrest) & II ()

```{r}

set.seed(123)
lgr::get_logger("mlr3")$set_threshold("warn")

obj_dml_data <- double_ml_data_from_data_frame(data_pension,
                                        y_col = "Y",
                                        d_cols = "W",
                                        x_cols = cols)


# Version 1
learner <-  lrn("regr.ranger", num.trees = 100, mtry = ncol(X)-1, min.node.size = 2, max.depth = 5)
# learner <- lrn("regr.ranger")
ml_l_plr_1 <-  learner$clone()
ml_m_plr_1 <-  learner$clone()


#Version 2
ml_l_plr_2 <- lrn("regr.ranger")
ml_m_plr_2 <- lrn("classif.ranger")




dml_plr_obj_1 <- DoubleMLPLR$new(obj_dml_data,
                               ml_l_plr_1,
                               ml_m_plr_1)
dml_plr_obj_1$fit()
print(dml_plr_obj_1)




# Initialize an object of class DoubleMLPLR
dml_plr_obj_2 <- DoubleMLPLR$new(obj_dml_data,
                                       ml_l_plr_2,
                                       ml_m_plr_2)

# Estimate the treatment effect
dml_plr_obj_2$fit()
print(dml_plr_obj_2)


```


## Partially linear IV regression model (PLIV)


### Version I () & II ()

```{r}

set.seed(123)

obj_dml_data_z <- DoubleMLData$new(data_pension,
                                     y_col="Y",
                                     d_col = "W",
                                     z_cols= "Z",
                                     x_cols = cols)
#version 1
learner <- lrn("regr.ranger", num.trees = 100, mtry = ncol(X)-1, min.node.size = 2, max.depth = 5)
ml_l_pliv_1 <- learner$clone()
ml_m_pliv_1 <- learner$clone()
ml_r_pliv_1 <- learner$clone()


#Version 2
learner <- lrn("regr.ranger", num.trees = 100, mtry = ncol(X)-1, min.node.size = 2, max.depth = 5)
ml_l_pliv_2 <- learner$clone()
ml_m_pliv_2 <- learner$clone()
ml_r_pliv_2 <- learner$clone()

#Version 1
dml_pliv_obj_1 <- DoubleMLPLIV$new(obj_dml_data_z,
                                ml_l_pliv_1,
                                ml_m_pliv_1,
                                ml_r_pliv_1)
dml_pliv_obj_1$fit()
print(dml_pliv_obj_1)


#Version 2
dml_pliv_obj_2 <- DoubleMLPLIV$new(obj_dml_data_z,
                                 ml_l_pliv_2,
                                 ml_m_pliv_2,
                                 ml_r_pliv_2)
dml_pliv_obj_2$fit()
print(dml_pliv_obj_2)



```


## Interactive regression model for ATE (IRM)

### Version I () & II ()

```{r}

set.seed(123)

obj_dml_data <-  DoubleMLData$new(data_pension,
                                y_col="Y",
                                d_cols="W",
                                x_cols = cols)
#Version 1
ml_g_irm_1 <-  lrn("regr.ranger", num.trees = 100, mtry = ncol(X)-1, min.node.size = 2, max.depth = 5)
ml_m_irm_1 <-  lrn("classif.ranger", num.trees = 100, mtry = ncol(X)-1, min.node.size = 2, max.depth = 5)

#Version 2
ml_g_irm_2 <-  lrn("regr.ranger", num.trees = 100, mtry = ncol(X)-1, min.node.size = 2, max.depth = 5)
ml_m_irm_2 <-  lrn("classif.ranger", num.trees = 100, mtry = ncol(X)-1, min.node.size = 2, max.depth = 5)

#Version 1
dml_irm_obj_1 <- DoubleMLIRM$new(obj_dml_data,
                                 ml_g_irm_1,
                                 ml_m_irm_1)
dml_irm_obj_1$fit()
print(dml_irm_obj_1)


#Version 2
dml_irm_obj_2 <- DoubleMLIRM$new(obj_dml_data,
                                 ml_g_irm_2,
                                 ml_m_irm_2)
dml_irm_obj_2$fit()
print(dml_irm_obj_2)




```




## Interactive IV model for LATE (IIVM)

This model uses three different machine learning learners: ml_g_iivm_1, ml_m_iivm_1, and ml_r_iivm_1. All three learners are based on the random forest algorithm (ranger), but they serve different purposes in the IIVM model.

ml_g_iivm_1 is a regression learner (regr.ranger) that is used to estimate the so-called “nuisance function” g0 in the first stage of the IIVM model. This function captures the relationship between the instrument variable(s) Z and the covariates X.

ml_m_iivm_1 is a classification learner (classif.ranger) that is used to estimate the nuisance function m0 in the first stage of the IIVM model. This function captures the relationship between the treatment variable(s) W and the covariates X.

ml_r_iivm_1 is a clone of ml_m_iivm_1 and is also a classification learner (classif.ranger). It is used to estimate another nuisance function r0 in the second stage of the IIVM model. This function captures how well we can predict Y from Z after controlling for X.

All three learners are random forests with 100 trees (num.trees = 100) and use all but one of the available predictor variables at each split (mtry = ncol(X)-1). The minimum size of terminal nodes is set to 2 (min.node.size = 2) and trees can grow up to a maximum depth of 5 (max.depth = 5).


### Version I () & II ()

```{r}

set.seed(123)

obj_dml_data_z <- DoubleMLData$new(data_pension,
                                y_col="Y",
                                d_cols="W",
                                z_cols="Z",
                                x_cols = cols)

#Version 1
ml_g_iivm_1 <-  lrn("regr.ranger", num.trees = 100, mtry = ncol(X)-1, min.node.size = 2, max.depth = 5)
ml_m_iivm_1 <-  lrn("classif.ranger", num.trees = 100, mtry = ncol(X)-1, min.node.size = 2, max.depth = 5)
ml_r_iivm_1 <-  ml_m_iivm_1$clone()

#Version 2
ml_g_iivm_2 <-  lrn("regr.ranger", num.trees = 100, mtry = ncol(X)-1, min.node.size = 2, max.depth = 5)
ml_m_iivm_2 <-  lrn("classif.ranger", num.trees = 100, mtry = ncol(X)-1, min.node.size = 2, max.depth = 5)
ml_r_iivm_2 <-  ml_m_iivm_2$clone()

#Version 1
dml_iivm_obj_1 <-  DoubleMLIIVM$new(obj_dml_data_z, 
                                    ml_g_iivm_1,
                                    ml_m_iivm_1,
                                    ml_r_iivm_1)
dml_iivm_obj_1$fit()
print(dml_iivm_obj_1)


#Version 2
dml_iivm_obj_2 <-  DoubleMLIIVM$new(obj_dml_data_z, 
                                    ml_g_iivm_2,
                                    ml_m_iivm_2,
                                    ml_r_iivm_2)
dml_iivm_obj_2$fit()
print(dml_iivm_obj_2)


```



## Model Evaluations

```{r}

dml_objs <- list(dml_plr_obj_1,dml_plr_obj_2,
                 dml_pliv_obj_1,dml_pliv_obj_2,
                 dml_irm_obj_1,dml_irm_obj_2,
                 dml_iivm_obj_1,dml_iivm_obj_2)
names <-c("PLR", "PLIV", "IRM", "IIVM")
model_names <- c(rep(names, each = 2),"IIVM_HPT")


point_estimates <- sapply(dml_objs, function(x) x$coef)
std_errors <- sapply(dml_objs, function(x) x$se)

#Add p-values for stat significance
p_values <- sapply(dml_objs, function(x) x$pval)

# point_estimates <- sapply(dml_objs, function(x) x$coef["W"])
# std_errors <- sapply(dml_objs, function(x) x$se["W"])


# calculate 95% confidence intervals
lower_bounds <- point_estimates - 1.96 * std_errors
upper_bounds <- point_estimates + 1.96 * std_errors


# create a data frame for plotting and model description
df <- data.frame(
    model = paste0("Model ", seq_along(dml_objs)," ",
                   model_names[1:length(dml_objs)]),
    estimate = point_estimates,
    lower = lower_bounds,
    upper = upper_bounds,
    p_value = p_values
)


# Determine the narrowest confidence Interval
# calculate the width of each confidence interval
ci_widths <- upper_bounds - lower_bounds
# find the index of the model with the slimest confidence interval width
best_model_idx <- which.min(ci_widths)
# get the name of the most secure model
best_model_name <- df$model[best_model_idx]
best_model_text <- paste0("The model with the narrowest confidence interval is: ", best_model_name)

# plot point estimates with error bars representing the confidence intervals
ggplot(df, aes(x=model, y=estimate)) +
    geom_point(aes(color=model), size=3) +
    geom_errorbar(aes(ymin=lower, ymax=upper), width=0.2, color="grey80") +
    scale_color_brewer(palette="Set1") +
    theme_light() +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
          axis.text.x = element_text(angle = 90)) + # rotate x-axis labels
    ggtitle("Model Evaluation") +
    labs(subtitle = best_model_text)+
    xlab("Model") +
    ylab("Point Estimate")


```
```{r}

# find the index of the model with the smallest p-value
best_model_idx <- which.min(df$p_value)

# get the name of the best model
best_model_name <- df$model[best_model_idx]

# create text for subtitle
best_model_text <- paste0("The model with highest statistical significance is: ", best_model_name)

# plot p-values for each model
ggplot(df, aes(x=model, y=p_value)) +
    geom_point(aes(color=model), size=3) +
    scale_color_brewer(palette="Set1") +
    theme_light() +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
          axis.text.x = element_text(angle = 90)) +
    ggtitle("Model Evaluation (p-values)") +
    labs(subtitle = best_model_text) + # add subtitle
    xlab("Model") +
    ylab("P-value")
```

A model may provide the best accurate estimate of the treatment impact if it has the narrowest confidence interval among the other models being compared. As a result, employing this model as opposed to other models, there is less doubt over the actual value of the treatment impact.
Based on this, we will now perform Hyperparameter tuning to determine if we can improve the model.


## Final Model (Hyperparameter Tunining)


```{r}

library(DoubleML)
library(mlr3)
library(mlr3tuning)

# Set up the data
obj_dml_data_pliv <- DoubleMLData$new(data_pension,
                                      y_col = "Y",
                                      d_col = "W",
                                      z_cols = "Z",
                                      x_cols = cols)

# Set up the learner
learner <- lrn("regr.ranger")

# Define the search space for hyperparameters
param_set <- ParamSet$new(list(
  ParamInt$new("num.trees", lower = 10, upper = 500),
  ParamInt$new("mtry", lower = 1, upper = ncol(obj_dml_data_pliv$data)-1),
  ParamInt$new("min.node.size", lower = 1, upper = 10),
  ParamInt$new("max.depth", lower = 1, upper = 10)
))

# Set up the tuning instance
instance <- TuningInstanceSingleCrit$new(
  task = TaskRegr$new(id = "pliv_task", backend=obj_dml_data_pliv$data,
                      target="Y"),
  learner = learner,
  resampling = rsmp("cv", folds=5),
  measure=msr("regr.mse"),
  search_space=param_set,
  terminator=trm("evals", n_evals=25)
)

# Run the tuning
tuner <- tnr("grid_search")
tuner$optimize(instance)

# Extract the best hyperparameters
best_params <- instance$result_learner_param_vals

# Update the learners with the best hyperparameters
ml_l_pliv <- learner$clone()
ml_l_pliv$param_set$values <-  best_params
ml_m_pliv <- learner$clone()
ml_m_pliv$param_set$values <- best_params
ml_r_pliv <- learner$clone()
ml_r_pliv$param_set$values <- best_params

dml_pliv_obj <- DoubleMLPLIV$new(obj_dml_data_pliv,
                                 ml_l_pliv,
                                 ml_m_pliv,
                                 ml_r_pliv)

dml_pliv_obj$fit()
print(dml_pliv_obj)


```



